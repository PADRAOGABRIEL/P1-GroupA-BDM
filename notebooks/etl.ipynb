{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc826c0-ff40-46d3-bc23-0bef641c5aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['yellow_tripdata_2025-01.parquet', 'yellow_tripdata_2025-02.parquet'], [])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col, current_timestamp, input_file_name, to_date, unix_timestamp\n",
    "\n",
    "INBOX = \"/home/jovyan/work/data/inbox\"\n",
    "OUTBOX = \"/home/jovyan/work/data/outbox/trips_enriched.parquet\"\n",
    "LOOKUP = \"/home/jovyan/work/data/taxi_zone_lookup.parquet\"\n",
    "STATE = \"/home/jovyan/work/state/manifest.json\"\n",
    "\n",
    "os.makedirs(\"/home/jovyan/work/state\", exist_ok=True)\n",
    "os.makedirs(\"/home/jovyan/work/data/outbox\", exist_ok=True)\n",
    "\n",
    "def load_manifest(path):\n",
    "    if not os.path.exists(path):\n",
    "        return {\"processed_files\": []}\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_manifest(path, manifest):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(manifest, f, indent=2)\n",
    "\n",
    "manifest = load_manifest(STATE)\n",
    "processed = set(x[\"filename\"] for x in manifest[\"processed_files\"])\n",
    "\n",
    "all_files = sorted([f for f in os.listdir(INBOX) if f.endswith(\".parquet\")])\n",
    "new_files = [f for f in all_files if f not in processed]\n",
    "\n",
    "all_files, new_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a2dbdaf-1b2d-4706-8da1-ab7271bbde58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yellow_tripdata_2025-01.parquet', 'yellow_tripdata_2025-02.parquet']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "INBOX = \"/home/jovyan/work/data/inbox\"\n",
    "\n",
    "os.listdir(INBOX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "999916b2-182d-446e-b369-015410584c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|       1| 2025-01-01 00:18:38|  2025-01-01 00:26:59|              1|          1.6|         1|                 N|         229|         237|           1|       10.0|  3.5|    0.5|       3.0|         0.0|                  1.0|        18.0|                 2.5|        0.0|               0.0|\n",
      "|       1| 2025-01-01 00:32:40|  2025-01-01 00:35:13|              1|          0.5|         1|                 N|         236|         237|           1|        5.1|  3.5|    0.5|      2.02|         0.0|                  1.0|       12.12|                 2.5|        0.0|               0.0|\n",
      "|       1| 2025-01-01 00:44:04|  2025-01-01 00:46:01|              1|          0.6|         1|                 N|         141|         141|           1|        5.1|  3.5|    0.5|       2.0|         0.0|                  1.0|        12.1|                 2.5|        0.0|               0.0|\n",
      "|       2| 2025-01-01 00:14:27|  2025-01-01 00:20:01|              3|         0.52|         1|                 N|         244|         244|           2|        7.2|  1.0|    0.5|       0.0|         0.0|                  1.0|         9.7|                 0.0|        0.0|               0.0|\n",
      "|       2| 2025-01-01 00:21:34|  2025-01-01 00:25:06|              3|         0.66|         1|                 N|         244|         116|           2|        5.8|  1.0|    0.5|       0.0|         0.0|                  1.0|         8.3|                 0.0|        0.0|               0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Project1-ETL\").getOrCreate()\n",
    "\n",
    "df = spark.read.parquet(\n",
    "    \"/home/jovyan/work/data/inbox/yellow_tripdata_2025-01.parquet\"\n",
    ")\n",
    "\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df4a6e8-86c8-4705-9b34-718563a912b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      " |-- cbd_congestion_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3123b95-0527-4963-a8d0-e995330b9c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3475226"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74aa0a5e-497b-4b24-a68e-647fd796d450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7052769"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = spark.read.parquet(\"/home/jovyan/work/data/inbox/*.parquet\")\n",
    "\n",
    "df_all.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944140e8-7a43-4e78-b03a-95b7547d6607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------------+---------------------+\n",
      "|passenger_count|trip_distance|tpep_pickup_datetime|tpep_dropoff_datetime|\n",
      "+---------------+-------------+--------------------+---------------------+\n",
      "|              1|          1.6| 2025-01-01 00:18:38|  2025-01-01 00:26:59|\n",
      "|              1|          0.5| 2025-01-01 00:32:40|  2025-01-01 00:35:13|\n",
      "|              1|          0.6| 2025-01-01 00:44:04|  2025-01-01 00:46:01|\n",
      "|              3|         0.52| 2025-01-01 00:14:27|  2025-01-01 00:20:01|\n",
      "|              3|         0.66| 2025-01-01 00:21:34|  2025-01-01 00:25:06|\n",
      "|              2|         2.63| 2025-01-01 00:48:24|  2025-01-01 01:08:26|\n",
      "|              0|          0.4| 2025-01-01 00:14:47|  2025-01-01 00:16:15|\n",
      "|              0|          1.6| 2025-01-01 00:39:27|  2025-01-01 00:51:51|\n",
      "|              0|          2.8| 2025-01-01 00:53:43|  2025-01-01 01:13:23|\n",
      "|              1|         1.71| 2025-01-01 00:00:02|  2025-01-01 00:09:36|\n",
      "+---------------+-------------+--------------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.select(\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\"\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb610915-e154-45b3-8cf4-c2b6023077f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_clean = df_all.filter(\n",
    "    (col(\"passenger_count\") > 0) &\n",
    "    (col(\"trip_distance\") > 0) &\n",
    "    (col(\"tpep_dropoff_datetime\") > col(\"tpep_pickup_datetime\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76b2634a-ba99-4847-9fec-7655b8bf917c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7052769, 5579927)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_before = df_all.count()\n",
    "total_after = df_clean.count()\n",
    "\n",
    "total_before, total_after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f545e441-39ab-4e98-bfbc-6a4acb2682af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------------+---------------------+\n",
      "|passenger_count|trip_distance|tpep_pickup_datetime|tpep_dropoff_datetime|\n",
      "+---------------+-------------+--------------------+---------------------+\n",
      "|              1|          0.0| 2025-01-01 11:50:50|  2025-01-01 11:51:06|\n",
      "|              1|          0.0| 2025-01-01 11:10:14|  2025-01-01 11:10:26|\n",
      "|              0|          2.8| 2025-01-01 12:07:26|  2025-01-01 12:17:45|\n",
      "|              1|          0.0| 2025-01-01 15:49:46|  2025-01-01 15:49:52|\n",
      "|              0|          1.4| 2025-01-02 10:54:05|  2025-01-02 11:05:11|\n",
      "+---------------+-------------+--------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_rows = df_all.subtract(df_clean)\n",
    "\n",
    "bad_rows.select(\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\"\n",
    ").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dcecd42-e398-459c-8c78-58245f40d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dedup = df_clean.dropDuplicates([\n",
    "    \"VendorID\",\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\",\n",
    "    \"PULocationID\",\n",
    "    \"DOLocationID\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ccde026-8a98-43d7-8a7c-6051598c9ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5579927, 5486133)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_clean = df_clean.count()\n",
    "count_dedup = df_dedup.count()\n",
    "\n",
    "count_clean, count_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cff0f99-1b9d-402a-8773-fc2bab37a289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- LocationID: long (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOOKUP = \"/home/jovyan/work/data/taxi_zone_lookup.parquet\"\n",
    "\n",
    "zones = spark.read.parquet(LOOKUP)\n",
    "\n",
    "zones.show(5)\n",
    "zones.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e01d071f-19c0-4e2f-8e29-15c80305919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "zones_pickup = (\n",
    "    zones\n",
    "    .select(col(\"LocationID\").alias(\"PULocationID\"),\n",
    "            col(\"Zone\").alias(\"pickup_zone\"))\n",
    ")\n",
    "\n",
    "df_enriched = df_dedup.join(\n",
    "    broadcast(zones_pickup),   # lookup é pequeno → melhora performance\n",
    "    on=\"PULocationID\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a261897e-55ef-4342-bdb6-261a79bd0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_dropoff = (\n",
    "    zones\n",
    "    .select(col(\"LocationID\").alias(\"DOLocationID\"),\n",
    "            col(\"Zone\").alias(\"dropoff_zone\"))\n",
    ")\n",
    "\n",
    "df_enriched = df_enriched.join(\n",
    "    broadcast(zones_dropoff),\n",
    "    on=\"DOLocationID\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c57835b0-6932-44c5-9ae5-defab6232436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------+------------+-----------------------------+\n",
      "|PULocationID|pickup_zone          |DOLocationID|dropoff_zone                 |\n",
      "+------------+---------------------+------------+-----------------------------+\n",
      "|142         |Lincoln Square East  |263         |Yorkville West               |\n",
      "|140         |Lenox Hill East      |50          |Clinton West                 |\n",
      "|239         |Upper West Side South|143         |Lincoln Square West          |\n",
      "|142         |Lincoln Square East  |239         |Upper West Side South        |\n",
      "|263         |Yorkville West       |249         |West Village                 |\n",
      "|263         |Yorkville West       |107         |Gramercy                     |\n",
      "|239         |Upper West Side South|41          |Central Harlem               |\n",
      "|162         |Midtown East         |141         |Lenox Hill West              |\n",
      "|137         |Kips Bay             |107         |Gramercy                     |\n",
      "|68          |East Chelsea         |158         |Meatpacking/West Village West|\n",
      "+------------+---------------------+------------+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_enriched.select(\n",
    "    \"PULocationID\", \"pickup_zone\",\n",
    "    \"DOLocationID\", \"dropoff_zone\"\n",
    ").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76721abf-83ab-4da4-95cc-653c54fd964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|pickup_zone_nulls|dropoff_zone_nulls|\n",
      "+-----------------+------------------+\n",
      "|                0|                 0|\n",
      "+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum as fsum, when\n",
    "\n",
    "null_zones = df_enriched.select(\n",
    "    fsum(when(col(\"pickup_zone\").isNull(), 1).otherwise(0)).alias(\"pickup_zone_nulls\"),\n",
    "    fsum(when(col(\"dropoff_zone\").isNull(), 1).otherwise(0)).alias(\"dropoff_zone_nulls\"),\n",
    ")\n",
    "\n",
    "null_zones.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11f8ff99-08b5-490f-84da-7a0e3b48e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import input_file_name\n",
    "\n",
    "df_all_with_source = df_all.withColumn(\"source_file\", input_file_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b8d09dc-d2fd-45e6-bcc6-5a9594de6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_clean = df_all_with_source.filter(\n",
    "    (col(\"passenger_count\") > 0) &\n",
    "    (col(\"trip_distance\") > 0) &\n",
    "    (col(\"tpep_dropoff_datetime\") > col(\"tpep_pickup_datetime\"))\n",
    ")\n",
    "\n",
    "df_dedup = df_clean.dropDuplicates([\n",
    "    \"VendorID\",\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\",\n",
    "    \"PULocationID\",\n",
    "    \"DOLocationID\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c5c1ed7-ef1b-4620-b38d-f8d9b490bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "zones_pickup = zones.select(\n",
    "    col(\"LocationID\").alias(\"PULocationID\"),\n",
    "    col(\"Zone\").alias(\"pickup_zone\")\n",
    ")\n",
    "\n",
    "zones_dropoff = zones.select(\n",
    "    col(\"LocationID\").alias(\"DOLocationID\"),\n",
    "    col(\"Zone\").alias(\"dropoff_zone\")\n",
    ")\n",
    "\n",
    "df_enriched = (\n",
    "    df_dedup\n",
    "    .join(broadcast(zones_pickup), \"PULocationID\", \"left\")\n",
    "    .join(broadcast(zones_dropoff), \"DOLocationID\", \"left\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6bcdff8-dd7d-4a47-90c2-6c3a09cf8043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, to_date, current_timestamp\n",
    "\n",
    "df_ready = (\n",
    "    df_enriched\n",
    "    .withColumn(\n",
    "        \"trip_duration_minutes\",\n",
    "        (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")) / 60.0\n",
    "    )\n",
    "    .withColumn(\"pickup_date\", to_date(\"tpep_pickup_datetime\"))\n",
    "    .withColumn(\"ingested_at\", current_timestamp())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8018bd2e-224d-4212-90d1-e244c9997c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+------------+-------------------------+------------+--------------+---------------+-------------+---------------------+-----------+-------------------------------------------------------------------+--------------------------+\n",
      "|tpep_pickup_datetime|tpep_dropoff_datetime|PULocationID|pickup_zone              |DOLocationID|dropoff_zone  |passenger_count|trip_distance|trip_duration_minutes|pickup_date|source_file                                                        |ingested_at               |\n",
      "+--------------------+---------------------+------------+-------------------------+------------+--------------+---------------+-------------+---------------------+-----------+-------------------------------------------------------------------+--------------------------+\n",
      "|2025-01-01 03:38:57 |2025-01-01 04:05:11  |230         |Times Sq/Theatre District|1           |Newark Airport|4              |17.91        |26.233333333333334   |2025-01-01 |file:///home/jovyan/work/data/inbox/yellow_tripdata_2025-01.parquet|2026-02-16 11:37:33.253527|\n",
      "|2025-01-01 03:39:52 |2025-01-01 04:10:36  |170         |Murray Hill              |1           |Newark Airport|1              |17.33        |30.733333333333334   |2025-01-01 |file:///home/jovyan/work/data/inbox/yellow_tripdata_2025-01.parquet|2026-02-16 11:37:33.253527|\n",
      "|2025-01-01 07:28:57 |2025-01-01 07:47:16  |45          |Chinatown                |1           |Newark Airport|2              |12.09        |18.316666666666666   |2025-01-01 |file:///home/jovyan/work/data/inbox/yellow_tripdata_2025-01.parquet|2026-02-16 11:37:33.253527|\n",
      "|2025-01-01 07:43:59 |2025-01-01 08:10:26  |87          |Financial District North |1           |Newark Airport|1              |16.15        |26.45                |2025-01-01 |file:///home/jovyan/work/data/inbox/yellow_tripdata_2025-01.parquet|2026-02-16 11:37:33.253527|\n",
      "|2025-01-01 09:12:07 |2025-01-01 09:41:39  |162         |Midtown East             |1           |Newark Airport|3              |18.28        |29.533333333333335   |2025-01-01 |file:///home/jovyan/work/data/inbox/yellow_tripdata_2025-01.parquet|2026-02-16 11:37:33.253527|\n",
      "+--------------------+---------------------+------------+-------------------------+------------+--------------+---------------+-------------+---------------------+-----------+-------------------------------------------------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ready.select(\n",
    "    \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\",\n",
    "    \"PULocationID\", \"pickup_zone\",\n",
    "    \"DOLocationID\", \"dropoff_zone\",\n",
    "    \"passenger_count\", \"trip_distance\",\n",
    "    \"trip_duration_minutes\", \"pickup_date\",\n",
    "    \"source_file\", \"ingested_at\"\n",
    ").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb47438c-c65a-4129-9ae4-439a6d2f0f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files: ['yellow_tripdata_2025-01.parquet', 'yellow_tripdata_2025-02.parquet']\n",
      "New files: []\n",
      "✅ Nothing new to process. Exiting without changes.\n"
     ]
    }
   ],
   "source": [
    "import os, json, shutil\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    col, input_file_name, current_timestamp, to_date, unix_timestamp, broadcast\n",
    ")\n",
    "\n",
    "# Paths (dentro do container)\n",
    "INBOX = \"/home/jovyan/work/data/inbox\"\n",
    "LOOKUP = \"/home/jovyan/work/data/taxi_zone_lookup.parquet\"\n",
    "OUTBOX = \"/home/jovyan/work/data/outbox/trips_enriched.parquet\"\n",
    "STATE = \"/home/jovyan/work/state/manifest.json\"\n",
    "\n",
    "os.makedirs(\"/home/jovyan/work/state\", exist_ok=True)\n",
    "os.makedirs(\"/home/jovyan/work/data/outbox\", exist_ok=True)\n",
    "\n",
    "def load_manifest(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        return {\"processed_files\": []}\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_manifest(path: str, manifest: dict):\n",
    "    tmp = path + \".tmp\"\n",
    "    with open(tmp, \"w\") as f:\n",
    "        json.dump(manifest, f, indent=2)\n",
    "    os.replace(tmp, path)  # escrita “atômica” (evita manifest corrompido)\n",
    "\n",
    "def outbox_has_data(path: str) -> bool:\n",
    "    return (\n",
    "        os.path.exists(path)\n",
    "        and os.path.isdir(path)\n",
    "        and any(name.startswith(\"part-\") and name.endswith(\".parquet\") for name in os.listdir(path))\n",
    "    )\n",
    "\n",
    "# (Opcional) se existir outbox vazio/corrompido, remove antes (evita UNABLE_TO_INFER_SCHEMA)\n",
    "if os.path.exists(OUTBOX) and not outbox_has_data(OUTBOX):\n",
    "    print(\"⚠️ OUTBOX exists but has no parquet parts. Deleting corrupted/empty outbox folder...\")\n",
    "    shutil.rmtree(OUTBOX)\n",
    "\n",
    "# 1) Descobrir arquivos novos\n",
    "manifest = load_manifest(STATE)\n",
    "processed = set(x[\"filename\"] for x in manifest[\"processed_files\"])\n",
    "\n",
    "all_files = sorted([f for f in os.listdir(INBOX) if f.endswith(\".parquet\")])\n",
    "new_files = [f for f in all_files if f not in processed]\n",
    "\n",
    "print(\"All files:\", all_files)\n",
    "print(\"New files:\", new_files)\n",
    "\n",
    "if not new_files:\n",
    "    print(\"✅ Nothing new to process. Exiting without changes.\")\n",
    "else:\n",
    "    now = datetime.utcnow().isoformat()\n",
    "\n",
    "    # 2) Ler SOMENTE os novos arquivos\n",
    "    new_paths = [os.path.join(INBOX, f) for f in new_files]\n",
    "    df_new = spark.read.parquet(*new_paths).withColumn(\"source_file\", input_file_name())\n",
    "\n",
    "    # 3) Limpeza\n",
    "    df_clean = df_new.filter(\n",
    "        (col(\"passenger_count\") > 0) &\n",
    "        (col(\"trip_distance\") > 0) &\n",
    "        (col(\"tpep_dropoff_datetime\") > col(\"tpep_pickup_datetime\"))\n",
    "    )\n",
    "\n",
    "    # 4) Dedup (nos novos)\n",
    "    dedup_key = [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"PULocationID\", \"DOLocationID\"]\n",
    "    df_dedup = df_clean.dropDuplicates(dedup_key)\n",
    "\n",
    "    # 5) Lookup + joins (broadcast pois lookup é pequeno)\n",
    "    zones = spark.read.parquet(LOOKUP)\n",
    "\n",
    "    zones_pickup = zones.select(\n",
    "        col(\"LocationID\").alias(\"PULocationID\"),\n",
    "        col(\"Zone\").alias(\"pickup_zone\")\n",
    "    )\n",
    "\n",
    "    zones_dropoff = zones.select(\n",
    "        col(\"LocationID\").alias(\"DOLocationID\"),\n",
    "        col(\"Zone\").alias(\"dropoff_zone\")\n",
    "    )\n",
    "\n",
    "    df_enriched = (\n",
    "        df_dedup\n",
    "        .join(broadcast(zones_pickup), \"PULocationID\", \"left\")\n",
    "        .join(broadcast(zones_dropoff), \"DOLocationID\", \"left\")\n",
    "    )\n",
    "\n",
    "    # 6) Derivadas + metadata\n",
    "    df_ready = (\n",
    "        df_enriched\n",
    "        .withColumn(\n",
    "            \"trip_duration_minutes\",\n",
    "            (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")) / 60.0\n",
    "        )\n",
    "        .withColumn(\"pickup_date\", to_date(\"tpep_pickup_datetime\"))\n",
    "        .withColumn(\"ingested_at\", current_timestamp())\n",
    "    )\n",
    "\n",
    "    # 7) Escrever APENAS o que é novo (APPEND) — mais leve, evita crash da JVM\n",
    "    # (Dica: coalesce reduz número de arquivos de saída e pressão de memória)\n",
    "    df_ready.coalesce(4).write.mode(\"append\").parquet(OUTBOX)\n",
    "\n",
    "    # 8) Atualizar manifest (idempotência)\n",
    "    # (opcional) salvar também rows após clean+dedup por arquivo — mas sem collect pesado\n",
    "    # aqui vamos salvar só o filename e timestamp (mínimo exigido)\n",
    "    for f in new_files:\n",
    "        manifest[\"processed_files\"].append({\n",
    "            \"filename\": f,\n",
    "            \"processed_at\": now\n",
    "        })\n",
    "\n",
    "    save_manifest(STATE, manifest)\n",
    "\n",
    "    print(\"✅ Run complete!\")\n",
    "    print(\"Output path:\", OUTBOX)\n",
    "    print(\"Manifest updated:\", STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5433a0d-63c5-4e50-86c9-018917160a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTBOX exists? True\n",
      "OUTBOX contents: ['.part-00000-3f0416c5-0c6e-4dbc-924b-9db42d02f3d4-c000.snappy.parquet.crc', '.part-00001-3f0416c5-0c6e-4dbc-924b-9db42d02f3d4-c000.snappy.parquet.crc', '.part-00002-3f0416c5-0c6e-4dbc-924b-9db42d02f3d4-c000.snappy.parquet.crc', '.part-00003-3f0416c5-0c6e-4dbc-924b-9db42d02f3d4-c000.snappy.parquet.crc', '._SUCCESS.crc', 'part-00000-3f0416c5-0c6e-4dbc-924b-9db42d02f3d4-c000.snappy.parquet', 'part-00001-3f0416c5-0c6e-4dbc-924b-9db42d02f3d4-c000.snappy.parquet', 'part-00002-3f0416c5-0c6e-4dbc-924b-9db42d02f3d4-c000.snappy.parquet', 'part-00003-3f0416c5-0c6e-4dbc-924b-9db42d02f3d4-c000.snappy.parquet', '_SUCCESS']\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "OUTBOX = \"/home/jovyan/work/data/outbox/trips_enriched.parquet\"\n",
    "\n",
    "print(\"OUTBOX exists?\", os.path.exists(OUTBOX))\n",
    "if os.path.exists(OUTBOX):\n",
    "    print(\"OUTBOX contents:\", os.listdir(OUTBOX)[:50])\n",
    "\n",
    "# Se existir mas não tiver part-*.parquet, apaga\n",
    "def outbox_has_data(path: str) -> bool:\n",
    "    return (\n",
    "        os.path.exists(path)\n",
    "        and os.path.isdir(path)\n",
    "        and any(name.startswith(\"part-\") and name.endswith(\".parquet\") for name in os.listdir(path))\n",
    "    )\n",
    "\n",
    "if os.path.exists(OUTBOX) and not outbox_has_data(OUTBOX):\n",
    "    print(\"⚠️ OUTBOX exists but has no parquet parts. Deleting corrupted/empty outbox folder...\")\n",
    "    shutil.rmtree(OUTBOX)\n",
    "    print(\"✅ Deleted. Now OUTBOX exists?\", os.path.exists(OUTBOX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "defed8eb-651c-4f6b-ac90-b3b56e7759d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5486133"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.parquet(\"/home/jovyan/work/data/outbox/trips_enriched.parquet\").count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
